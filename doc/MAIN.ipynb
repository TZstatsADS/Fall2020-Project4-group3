{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "### Group 3\n",
    "### 12/04/20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction: The gole of the project is to test multiple causal inference models (Weighted Regression, Stratification and, Regression Adjustment) to see which one is best suited for the generated data sets (low dimentiona and high demenction datasets).  \n",
    "After clross validating to get the best auccearcy/estimated expected level of fit of the model to the data set that is independent of the data that were used to train the model. We used the cross validated generated propencity scores to model the causal inference and found the best Causal inference model based on the ATE scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages needed for study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "listpack = []\n",
    "# For illustrative purposes.\n",
    "\n",
    "pack_name = \"sklearn.linear_model os json numpy pandas time gc psutil statsmodels.api sklearn\".split()\n",
    "\n",
    "for packages in pack_name:\n",
    "    spec = importlib.util.find_spec(packages)\n",
    "    if spec is None:\n",
    "        listpack.append(pack_name)\n",
    "if len(listpack) != 0:\n",
    "    listpack = listpack[0]\n",
    "for packages in listpack:\n",
    "    globals()[packages] = __import__(packages) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validating to get the accurate propencity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 180 candidates, totalling 9000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done  36 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=7)]: Done 186 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=7)]: Done 436 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=7)]: Done 786 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=7)]: Done 1236 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=7)]: Done 1786 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=7)]: Done 2436 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=7)]: Done 3186 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=7)]: Done 4036 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=7)]: Done 4986 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=7)]: Done 6036 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=7)]: Done 7186 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=7)]: Done 8436 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=7)]: Done 9000 out of 9000 | elapsed: 14.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=10, n_splits=5, random_state=111),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('classifier_scale',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('classifier_SelectFromModel',\n",
       "                                        SelectFromModel(estimator=LogisticRegression(C=1.0,\n",
       "                                                                                     class_weight=None,\n",
       "                                                                                     dual=False,\n",
       "                                                                                     fit_intercept=True,\n",
       "                                                                                     intercept...\n",
       "             param_grid={'classifier_SelectFromModel__estimator__C': array([2.e-01, 4.e-01, 6.e-01, 8.e-01, 1.e+00, 2.e+00, 4.e+00, 6.e+00,\n",
       "       8.e+00, 1.e+01, 2.e-02, 4.e-02, 6.e-02, 8.e-02, 1.e-01, 2.e-03,\n",
       "       4.e-03, 6.e-03, 8.e-03, 1.e-02]),\n",
       "                         'classifier_classifier__max_features': array([10, 20, 30, 40, 50, 60, 70, 80, 90])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../data\")\n",
    "os.getcwd()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "seed = 111\n",
    "lowdim = pd.read_csv(\"lowDim_dataset.csv\")\n",
    "y  = lowdim[\"A\"]\n",
    "X = lowdim.drop(\"A\", axis = 1)\n",
    "X = X.drop(\"Y\", axis = 1)\n",
    "\n",
    "LR_L2 = LogisticRegression(penalty='l2', C=1.0, random_state=seed, solver='saga', max_iter=1e5)\n",
    "pipeline = Pipeline([('classifier_scale', StandardScaler()),\n",
    "                     ('classifier_SelectFromModel', SelectFromModel(LR_L2)),\n",
    "                     ('classifier_classifier', RandomForestClassifier(n_estimators=500, random_state=seed))])\n",
    "Lambda = np.array([])\n",
    "for i in [1e-1, 1, 1e-2, 1e-3]:\n",
    "    Lambda = np.append(Lambda, i * np.arange(2, 11, 2))\n",
    "param_grid = {'classifier_SelectFromModel__estimator__C': Lambda,\n",
    "              'classifier_classifier__max_features': np.arange(10,100, 10)}\n",
    "clf = GridSearchCV(pipeline, param_grid, scoring='roc_auc', n_jobs=7, cv=RepeatedStratifiedKFold(random_state=seed),\n",
    "                   verbose=1)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.09121429e-01, 1.54500000e-01, 7.27000000e-01, 1.16000000e-01,\n",
       "       6.64000000e-01, 0.00000000e+00, 6.08000000e-02, 8.89200000e-01,\n",
       "       6.54579335e-02, 7.78233333e-01, 6.71333333e-01, 2.26000000e-01,\n",
       "       1.22500000e-01, 5.00000000e-02, 7.92571429e-01, 1.87000000e-01,\n",
       "       8.90500000e-01, 6.98000000e-01, 4.00000000e-02, 5.23333333e-02,\n",
       "       6.77333333e-01, 9.40000000e-02, 2.20000000e-02, 1.14000000e-01,\n",
       "       7.80000000e-01, 4.39738095e-01, 0.00000000e+00, 1.88000000e-01,\n",
       "       8.76000000e-01, 1.57333333e-01, 2.43333333e-02, 2.14000000e-01,\n",
       "       7.52333333e-02, 1.00000000e-02, 6.78000000e-01, 8.00000000e-02,\n",
       "       4.20000000e-02, 8.00000000e-03, 7.16000000e-01, 7.30000000e-02,\n",
       "       1.40000000e-02, 4.80000000e-02, 5.23333333e-02, 7.51833333e-01,\n",
       "       2.65333333e-01, 8.34000000e-01, 1.12000000e-01, 1.01166667e-01,\n",
       "       9.96666667e-02, 7.63333333e-02, 2.80000000e-02, 3.60000000e-02,\n",
       "       1.60000000e-02, 3.86666667e-02, 2.54000000e-01, 1.25333333e-01,\n",
       "       3.36333333e-02, 5.09121429e-01, 1.00300000e-01, 1.35800000e-01,\n",
       "       9.71428571e-04, 8.25600000e-01, 1.52166667e-01, 1.31000000e-01,\n",
       "       9.80000000e-02, 7.26000000e-01, 7.63666667e-01, 8.33500000e-01,\n",
       "       6.00000000e-02, 0.00000000e+00, 1.98000000e-01, 3.35000000e-02,\n",
       "       4.00000000e-03, 4.00000000e-03, 0.00000000e+00, 5.01142857e-01,\n",
       "       0.00000000e+00, 4.00000000e-03, 2.22333333e-01, 6.92666667e-01,\n",
       "       0.00000000e+00, 1.68300000e-01, 0.00000000e+00, 8.72000000e-01,\n",
       "       8.32700000e-01, 7.86666667e-02, 8.57500000e-01, 0.00000000e+00,\n",
       "       1.22000000e-01, 7.11500000e-01, 0.00000000e+00, 2.00000000e-03,\n",
       "       9.00800000e-01, 1.22000000e-01, 7.25000000e-02, 8.73333333e-02,\n",
       "       8.70000000e-01, 7.18733333e-01, 6.60000000e-02, 5.99666667e-02,\n",
       "       8.40000000e-02, 5.95558608e-02, 8.30000000e-02, 5.28700000e-01,\n",
       "       6.54579335e-02, 1.96000000e-01, 9.30000000e-02, 8.07000000e-01,\n",
       "       4.00000000e-03, 8.20000000e-02, 1.52000000e-01, 2.00000000e-03,\n",
       "       8.62000000e-01, 6.54579335e-02, 2.14000000e-01, 2.40000000e-01,\n",
       "       1.30000000e-01, 9.64000000e-01, 2.60000000e-02, 6.79444167e-02,\n",
       "       1.42000000e-01, 1.66000000e-01, 6.54579335e-02, 2.00000000e-03,\n",
       "       5.20000000e-02, 7.26000000e-01, 1.16000000e-01, 4.00000000e-03,\n",
       "       4.00000000e-03, 0.00000000e+00, 9.34000000e-01, 6.86122222e-01,\n",
       "       1.40000000e-02, 7.40000000e-02, 3.17300000e-01, 1.60333333e-01,\n",
       "       1.09800000e-01, 1.32666667e-01, 9.60000000e-02, 4.39738095e-01,\n",
       "       0.00000000e+00, 2.00000000e-02, 7.43500000e-01, 1.46666667e-01,\n",
       "       2.40000000e-02, 6.54579335e-02, 0.00000000e+00, 2.00000000e-03,\n",
       "       0.00000000e+00, 9.24000000e-01, 7.50000000e-02, 0.00000000e+00,\n",
       "       1.02833333e-01, 8.20000000e-01, 4.60000000e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 7.36000000e-01, 2.68000000e-01, 7.97200000e-01,\n",
       "       1.26000000e-01, 1.00000000e-02, 6.74000000e-01, 3.80000000e-02,\n",
       "       6.00000000e-03, 5.01142857e-01, 1.92000000e-01, 9.71428571e-04,\n",
       "       1.35800000e-01, 2.82666667e-01, 0.00000000e+00, 3.02766667e-01,\n",
       "       1.80000000e-02, 7.77200000e-01, 6.54579335e-02, 6.54579335e-02,\n",
       "       5.00000000e-02, 7.93833333e-01, 6.52000000e-01, 3.60000000e-02,\n",
       "       2.00000000e-03, 9.73333333e-02, 7.53149206e-01, 7.22333333e-02,\n",
       "       1.75000000e-01, 1.48900000e-01, 2.02100133e-01, 0.00000000e+00,\n",
       "       1.60833333e-01, 6.54579335e-02, 1.10000000e-01, 2.87333333e-01,\n",
       "       6.54579335e-02, 7.66333333e-01, 5.70000000e-02, 0.00000000e+00,\n",
       "       1.80000000e-02, 6.60000000e-01, 2.80000000e-02, 3.20000000e-02,\n",
       "       1.80000000e-02, 0.00000000e+00, 8.85714286e-04, 4.20000000e-02,\n",
       "       2.00000000e-03, 7.43166667e-01, 2.22515079e-01, 2.00000000e-03,\n",
       "       7.81500000e-01, 2.00000000e-03, 8.00000000e-03, 5.00000000e-02,\n",
       "       2.80000000e-02, 9.20000000e-02, 1.92166667e-01, 5.70000000e-02,\n",
       "       1.45000000e-02, 4.80000000e-02, 1.68000000e-02, 8.20833333e-02,\n",
       "       9.00000000e-02, 1.60000000e-01, 2.02100133e-01, 0.00000000e+00,\n",
       "       1.69333333e-01, 8.72766667e-01, 7.27333333e-01, 4.80000000e-02,\n",
       "       1.29500000e-01, 2.44444444e-03, 2.00000000e-03, 7.06000000e-01,\n",
       "       4.60000000e-02, 6.54579335e-02, 7.25000000e-01, 7.38666667e-01,\n",
       "       2.33100000e-01, 0.00000000e+00, 0.00000000e+00, 2.80000000e-03,\n",
       "       1.80000000e-02, 8.14000000e-01, 5.60000000e-02, 3.36333333e-02,\n",
       "       5.01838095e-01, 1.34000000e-01, 5.01838095e-01, 1.60000000e-01,\n",
       "       6.36000000e-01, 4.00000000e-03, 7.20000000e-02, 1.73766667e-01,\n",
       "       1.10000000e-01, 6.54579335e-02, 5.00747619e-01, 7.40000000e-02,\n",
       "       7.22000000e-01, 7.40333333e-01, 3.30000000e-01, 4.00000000e-03,\n",
       "       0.00000000e+00, 6.54579335e-02, 0.00000000e+00, 2.00000000e-03,\n",
       "       2.20000000e-02, 2.00000000e-03, 6.74000000e-01, 4.00000000e-03,\n",
       "       7.20000000e-02, 3.80000000e-02, 9.38000000e-01, 8.74666667e-01,\n",
       "       5.28700000e-01, 2.02100133e-01, 7.20000000e-02, 2.09833333e-01,\n",
       "       1.00000000e-02, 4.00000000e-03, 6.00000000e-03, 6.82000000e-01,\n",
       "       7.91500000e-01, 1.32666667e-01, 1.40000000e-02, 2.55196888e-02,\n",
       "       3.46269841e-02, 8.20000000e-02, 4.20000000e-02, 7.41300000e-01,\n",
       "       0.00000000e+00, 6.40000000e-01, 7.36000000e-01, 2.60333333e-01,\n",
       "       8.62333333e-01, 2.00000000e-03, 0.00000000e+00, 3.89285714e-03,\n",
       "       3.00000000e-02, 9.96666667e-02, 1.22000000e-01, 6.44000000e-01,\n",
       "       1.78000000e-01, 9.38000000e-01, 1.70000000e-01, 4.20000000e-02,\n",
       "       2.80000000e-02, 5.30000000e-02, 2.30095238e-01, 1.00333333e-01,\n",
       "       4.70000000e-02, 9.00000000e-02, 4.00000000e-03, 1.00000000e-02,\n",
       "       2.00000000e-03, 2.43333333e-02, 6.00000000e-03, 1.42666667e-01,\n",
       "       7.12000000e-01, 1.04500000e-01, 2.52000000e-01, 3.60000000e-02,\n",
       "       7.44633333e-01, 1.83000000e-01, 5.00747619e-01, 0.00000000e+00,\n",
       "       7.39033333e-01, 2.62000000e-01, 7.73666667e-01, 4.00000000e-03,\n",
       "       2.00166667e-01, 1.20000000e-02, 4.80000000e-02, 4.07190476e-02,\n",
       "       1.98000000e-01, 4.00000000e-03, 3.20000000e-02, 9.80000000e-02,\n",
       "       8.08000000e-01, 1.80000000e-02, 8.60000000e-02, 9.80000000e-02,\n",
       "       7.20000000e-02, 2.00000000e-03, 6.54579335e-02, 0.00000000e+00,\n",
       "       2.80000000e-02, 1.47000000e-01, 1.60000000e-01, 7.14333333e-01,\n",
       "       7.92000000e-01, 4.00000000e-03, 1.24914286e-01, 7.95166667e-01,\n",
       "       8.80000000e-02, 4.71866667e-01, 0.00000000e+00, 8.02166667e-01,\n",
       "       2.05000000e-01, 7.66000000e-01, 6.81933333e-01, 6.72000000e-01,\n",
       "       1.85666667e-01, 7.20000000e-01, 4.60000000e-02, 1.03333333e-02,\n",
       "       3.40000000e-02, 1.10000000e-01, 7.49333333e-01, 4.20000000e-02,\n",
       "       1.99666667e-01, 2.40000000e-02, 2.10000000e-02, 2.70000000e-02,\n",
       "       2.01000000e-01, 8.40000000e-02, 2.02100133e-01, 7.40000000e-02,\n",
       "       2.40000000e-02, 6.20000000e-02, 6.23333333e-02, 9.16000000e-01,\n",
       "       8.85245789e-02, 6.46000000e-01, 6.56000000e-01, 2.02100133e-01,\n",
       "       4.80000000e-02, 0.00000000e+00, 4.00000000e-03, 7.70000000e-02,\n",
       "       4.71866667e-01, 1.04833333e-01, 1.75333333e-01, 2.00000000e-03,\n",
       "       4.00000000e-03, 1.14000000e-01, 7.38000000e-01, 1.90000000e-02,\n",
       "       7.25333333e-01, 5.05333333e-02, 8.23100000e-01, 2.60000000e-02,\n",
       "       3.80000000e-02, 6.30000000e-02, 7.81666667e-01, 9.67727273e-02,\n",
       "       2.10000000e-02, 1.20000000e-02, 3.86666667e-02, 6.78000000e-01,\n",
       "       1.29333333e-01, 3.57000000e-02, 6.90823810e-01, 6.54579335e-02,\n",
       "       2.74533333e-01, 9.20000000e-02, 0.00000000e+00, 8.06000000e-01,\n",
       "       1.47333333e-01, 6.70500000e-01, 6.54579335e-02, 2.20000000e-02,\n",
       "       1.20633333e-01, 1.46000000e-01, 2.41966667e-01, 0.00000000e+00,\n",
       "       2.65333333e-01, 4.80000000e-02, 4.00000000e-03, 1.40000000e-02,\n",
       "       0.00000000e+00, 8.80000000e-02, 0.00000000e+00, 2.08933333e-01,\n",
       "       8.09800000e-01, 1.05866667e-01, 2.60000000e-02, 2.57000000e-01,\n",
       "       0.00000000e+00, 2.00000000e-03, 2.00000000e-03, 8.60000000e-02,\n",
       "       0.00000000e+00, 6.42000000e-01, 8.21933333e-01, 0.00000000e+00,\n",
       "       6.54579335e-02, 7.90000000e-02, 7.10000000e-01, 1.00000000e-02,\n",
       "       2.70000000e-01, 1.24000000e-01, 3.00000000e-02, 9.26666667e-02,\n",
       "       8.00000000e-03, 7.36000000e-01, 1.68233333e-01, 4.23714286e-02,\n",
       "       7.63333333e-02, 2.00000000e-03, 2.00000000e-03, 1.54800000e-01,\n",
       "       8.20000000e-02, 2.51111111e-02, 2.40000000e-02, 1.00000000e-02,\n",
       "       1.40000000e-02, 9.16000000e-01, 1.71916667e-01, 2.00000000e-03,\n",
       "       7.45500000e-01, 7.94000000e-01, 7.48833333e-01, 7.93833333e-01,\n",
       "       7.47000000e-01, 1.97666667e-01, 2.42000000e-01])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in Data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propensity Scores and L2 Regulirized Regression (crossvalidation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal Inference Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-81ea43cee7c3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-81ea43cee7c3>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Conclusion: AUC, Auccary, Run time, ATE\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Conclusion: AUC, Auccary, Run time, ATE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
